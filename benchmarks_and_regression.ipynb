{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "from tensorflow.compat.v1.keras import layers\n",
    "import tensorflow.compat.v1 as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from tf_graph_util import convert_variables_to_constants\n",
    "from lstm import create_lstm\n",
    "\n",
    "from seq2seq import create_seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def benchmark_model(model, cmd=None):\n",
    "    bench_path = f\"{model.name}_benchmark.txt\"\n",
    "    if not os.path.exists(f\"{model.name}.pbtxt\") and not os.path.exists(bench_path):\n",
    "        if not os.path.exists(f\"{model.name}.pbtxt\"):\n",
    "            print(\"Saving model...\")\n",
    "            tf.keras.backend.clear_session()\n",
    "            sess = tf.keras.backend.get_session()\n",
    "    #         output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            output_graph_def = convert_variables_to_constants(\n",
    "                sess,\n",
    "                sess.graph.as_graph_def(),\n",
    "                [node.op.name for node in model.outputs])\n",
    "            tf.io.write_graph(output_graph_def, './', f'{model.name}.pbtxt')\n",
    "        else:\n",
    "            print(\"Retrieving saved model.\")\n",
    "    \n",
    "    \n",
    "        if not os.path.exists(bench_path):\n",
    "            if not cmd:\n",
    "                input_shape = f\"1,{','.join(str(dim) for dim in model.input.shape[1:])}\"\n",
    "                cmd = f'../tensorflow/bazel-bin/tensorflow/tools/benchmark/benchmark_model --graph={model.name}.pbtxt --input_layer=\"{model.input.name}\" --input_layer_shape=\"{input_shape}\" --output_layer=\"{model.output.name}\"'\n",
    "                print(cmd)\n",
    "            print(\"Running benchmark...\")\n",
    "            benchmark = subprocess.run([cmd], stderr=subprocess.PIPE, shell=True)\n",
    "            print(\"Done.\")\n",
    "\n",
    "            output = benchmark.stderr.decode('unicode_escape')\n",
    "            split_output = output[output.find('Run Order'):output.find('Top by Computation Time')].split('\\n')\n",
    "\n",
    "            with open(bench_path, 'w') as f:\n",
    "                f.write(\"\\n\".join(split_output[1:-2]))\n",
    "        else:\n",
    "            print(\"Retrieving saved benchmark results.\")\n",
    "    else:\n",
    "        print(\"Retrieving saved model and benchmark results.\")\n",
    "    \n",
    "    f = open(bench_path)\n",
    "    benchmark = pd.read_csv(f, sep=\"\\t\").rename(columns=lambda x: x.strip())\n",
    "    benchmark = benchmark.drop(benchmark.columns[0], axis=1)\n",
    "    benchmark['name'] = benchmark['[Name]'].apply(lambda x: x.split('/')[0])\n",
    "    return benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_layer_features(model):\n",
    "    layers = pd.DataFrame()\n",
    "    layers['name'] = pd.Series([layer.name for layer in model.layers])\n",
    "    \n",
    "#     input_dims = {layer.name: [dim.value for dim in layer.input.shape.dims] for layer in model.layers}\n",
    "    \n",
    "#     layers['input_shape'] = pd.Series([[dim.value for dim in layer.input.shape.dims] for layer in model.layers])\n",
    "#     layers['output_shape'] = pd.Series([[dim.value for dim in layer.output.shape.dims] for layer in model.layers])\n",
    "    layers['input_shape'] = pd.Series([layer.input_shape for layer in model.layers])\n",
    "    layers['output_shape'] = pd.Series([layer.output_shape for layer in model.layers])\n",
    "\n",
    "    features = ['units','filters','activation','strides','kernel_size']\n",
    "    for feature in features:\n",
    "        layers[feature] = pd.Series(\n",
    "            [layer.get_config()[feature] if feature in layer.get_config() else None for layer in model.layers])\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def join_benchmark(features, benchmark):\n",
    "    speed = benchmark[['name', '[avg ms]']].groupby('name').sum()\n",
    "    mem = benchmark[['name', '[mem KB]']].groupby('name').max()\n",
    "    \n",
    "    return features.join(speed, on='name').join(mem, on='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def flatten_shape(shape):\n",
    "    if not shape:\n",
    "        return None\n",
    "    \n",
    "    def reduce(tup):\n",
    "        acc = 1\n",
    "        for val in tup:\n",
    "            if val:\n",
    "                acc *= val\n",
    "        return acc\n",
    "    \n",
    "    if isinstance(shape, list):\n",
    "        return sum(reduce(tup) for tup in shape)\n",
    "    \n",
    "    return reduce(shape)\n",
    "\n",
    "\n",
    "def clean(data):\n",
    "    cleaned = pd.get_dummies(\n",
    "        data.dropna(subset=['[avg ms]', '[mem KB]']), columns=['activation'], dummy_na=True)\n",
    "    \n",
    "\n",
    "    cleaned['input_size'] = cleaned['input_shape'].apply(flatten_shape)\n",
    "    cleaned['output_size'] = cleaned['output_shape'].apply(flatten_shape)\n",
    "    cleaned['stride_size'] = cleaned['strides'].apply(flatten_shape)\n",
    "    cleaned['kernel_size'] = cleaned['kernel_size'].apply(flatten_shape)\n",
    "\n",
    "    return cleaned.fillna(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rf_regression_model(data, column):\n",
    "    X = data.drop(['name', '[avg ms]', '[mem KB]', 'input_shape', 'output_shape', 'strides'], axis=1)  # Features\n",
    "    y = data[column]  # Labels\n",
    "\n",
    "    # Split dataset into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state = RANDOM_SEED) # 70% training and 30% test\n",
    "\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    rf = RandomForestRegressor(n_estimators = 1000, random_state = RANDOM_SEED)\n",
    "    # Train the model on training data\n",
    "    rf.fit(X_train, y_train);\n",
    "\n",
    "    return rf, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "def stacked_regression_model(data, column):\n",
    "\n",
    "    X = data.drop(['name', '[avg ms]', '[mem KB]', 'input_shape', 'output_shape', 'strides'], axis=1)  # Features\n",
    "    y = data[column]  # Labels\n",
    "\n",
    "    estimators = [\n",
    "        ('rf', RandomForestRegressor(n_estimators=1000, random_state=RANDOM_SEED)),\n",
    "        ('lr', RidgeCV()),\n",
    "        ('svr', LinearSVR(random_state=42)),\n",
    "        \n",
    "    ]\n",
    "    reg = StackingRegressor(\n",
    "        estimators=estimators,\n",
    "#         final_estimator=RandomForestRegressor(n_estimators=1000, random_state=RANDOM_SEED)\n",
    "    )\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    reg.fit(X_train, y_train).score(X_test, y_test)\n",
    "    \n",
    "    return reg, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def stacked_regression_model_2(data, column):\n",
    "\n",
    "    X = data.drop(['name', '[avg ms]', '[mem KB]', 'input_shape', 'output_shape', 'strides'], axis=1)  # Features\n",
    "    y = data[column]  # Labels\n",
    "    \n",
    "    poly = Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=5)),\n",
    "        ('linear', LinearRegression(fit_intercept=False))\n",
    "    ])\n",
    "\n",
    "    estimators = [\n",
    "        ('poly', poly),\n",
    "        ('lr', RidgeCV()),\n",
    "        ('svr', LinearSVR(random_state=42)),\n",
    "        \n",
    "    ]\n",
    "    reg = StackingRegressor(\n",
    "        estimators=estimators,\n",
    "#         final_estimator=RandomForestRegressor(n_estimators=1000, random_state=RANDOM_SEED)\n",
    "    )\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    reg.fit(X_train, y_train).score(X_test, y_test)\n",
    "    \n",
    "    return reg, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/brian/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session() # IMPORTANT for layer names to match up.\n",
    "model = tf.keras.applications.vgg16.VGG16(\n",
    "    include_top=True,\n",
    "    weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving saved model and benchmark results.\n"
     ]
    }
   ],
   "source": [
    "benchmark = benchmark_model(model)\n",
    "features = get_layer_features(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_df = join_benchmark(features, benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving saved model and benchmark results.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session() # IMPORTANT for layer names to match up.\n",
    "tf.keras.backend.set_learning_phase(0)\n",
    "inception = tf. keras.applications.inception_v3.InceptionV3(\n",
    "    include_top=True, weights='imagenet')\n",
    "inception_benchmark = benchmark_model(inception)\n",
    "inception_features = get_layer_features(inception)\n",
    "inception_df = join_benchmark(inception_features, inception_benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # lstm.summary()\n",
    "\n",
    "# tf.keras.backend.clear_session() # IMPORTANT for layer names to match up.\n",
    "\n",
    "# lstm = create_lstm()\n",
    "\n",
    "# # tf.keras.backend.set_learning_phase(0)\n",
    "# lstm_benchmark = benchmark_model(lstm)\n",
    "# lstm_features = get_layer_features(lstm)\n",
    "# lstm_df = join_benchmark(lstm_features, lstm_benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>output_shape</th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>activation</th>\n",
       "      <th>strides</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>[avg ms]</th>\n",
       "      <th>[mem KB]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>batch_normalization_28</td>\n",
       "      <td>(None, 35, 35, 96)</td>\n",
       "      <td>(None, 35, 35, 96)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>activation_35</td>\n",
       "      <td>(None, 17, 17, 128)</td>\n",
       "      <td>(None, 17, 17, 128)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.849</td>\n",
       "      <td>147.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>conv2d_89</td>\n",
       "      <td>(None, 8, 8, 2048)</td>\n",
       "      <td>(None, 8, 8, 448)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>448.0</td>\n",
       "      <td>linear</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>activation_84</td>\n",
       "      <td>(None, 8, 8, 192)</td>\n",
       "      <td>(None, 8, 8, 192)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.719</td>\n",
       "      <td>49.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>batch_normalization_45</td>\n",
       "      <td>(None, 17, 17, 160)</td>\n",
       "      <td>(None, 17, 17, 160)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>activation_61</td>\n",
       "      <td>(None, 17, 17, 192)</td>\n",
       "      <td>(None, 17, 17, 192)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.203</td>\n",
       "      <td>221.952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>mixed10</td>\n",
       "      <td>[(None, 8, 8, 320), (None, 8, 8, 768), (None, ...</td>\n",
       "      <td>(None, 8, 8, 2048)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.159</td>\n",
       "      <td>524.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>batch_normalization_15</td>\n",
       "      <td>(None, 35, 35, 64)</td>\n",
       "      <td>(None, 35, 35, 64)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>batch_normalization_84</td>\n",
       "      <td>(None, 8, 8, 192)</td>\n",
       "      <td>(None, 8, 8, 192)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>max_pooling2d_2</td>\n",
       "      <td>(None, 35, 35, 288)</td>\n",
       "      <td>(None, 17, 17, 288)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.340</td>\n",
       "      <td>332.928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  \\\n",
       "91   batch_normalization_28   \n",
       "106           activation_35   \n",
       "280               conv2d_89   \n",
       "278           activation_84   \n",
       "137  batch_normalization_45   \n",
       "207           activation_61   \n",
       "310                 mixed10   \n",
       "42   batch_normalization_15   \n",
       "274  batch_normalization_84   \n",
       "99          max_pooling2d_2   \n",
       "\n",
       "                                           input_shape         output_shape  \\\n",
       "91                                  (None, 35, 35, 96)   (None, 35, 35, 96)   \n",
       "106                                (None, 17, 17, 128)  (None, 17, 17, 128)   \n",
       "280                                 (None, 8, 8, 2048)    (None, 8, 8, 448)   \n",
       "278                                  (None, 8, 8, 192)    (None, 8, 8, 192)   \n",
       "137                                (None, 17, 17, 160)  (None, 17, 17, 160)   \n",
       "207                                (None, 17, 17, 192)  (None, 17, 17, 192)   \n",
       "310  [(None, 8, 8, 320), (None, 8, 8, 768), (None, ...   (None, 8, 8, 2048)   \n",
       "42                                  (None, 35, 35, 64)   (None, 35, 35, 64)   \n",
       "274                                  (None, 8, 8, 192)    (None, 8, 8, 192)   \n",
       "99                                 (None, 35, 35, 288)  (None, 17, 17, 288)   \n",
       "\n",
       "     units  filters activation strides kernel_size  [avg ms]  [mem KB]  \n",
       "91     NaN      NaN       None    None        None     0.007     0.000  \n",
       "106    NaN      NaN       relu    None        None     0.849   147.968  \n",
       "280    NaN    448.0     linear  (1, 1)      (1, 1)     0.002     0.000  \n",
       "278    NaN      NaN       relu    None        None     0.719    49.152  \n",
       "137    NaN      NaN       None    None        None     0.005     0.000  \n",
       "207    NaN      NaN       relu    None        None     1.203   221.952  \n",
       "310    NaN      NaN       None    None        None     0.159   524.288  \n",
       "42     NaN      NaN       None    None        None     0.003     0.000  \n",
       "274    NaN      NaN       None    None        None     0.003     0.000  \n",
       "99     NaN      NaN       None  (2, 2)        None     0.340   332.928  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([vgg_df, inception_df])\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>output_shape</th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>strides</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>[avg ms]</th>\n",
       "      <th>[mem KB]</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>block1_conv1</td>\n",
       "      <td>(None, 224, 224, 3)</td>\n",
       "      <td>(None, 224, 224, 64)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.657</td>\n",
       "      <td>12845.056</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>3211264</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>block1_conv2</td>\n",
       "      <td>(None, 224, 224, 64)</td>\n",
       "      <td>(None, 224, 224, 64)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.123</td>\n",
       "      <td>12845.056</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3211264</td>\n",
       "      <td>3211264</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>block1_pool</td>\n",
       "      <td>(None, 224, 224, 64)</td>\n",
       "      <td>(None, 112, 112, 64)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.437</td>\n",
       "      <td>3211.264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3211264</td>\n",
       "      <td>802816</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>block2_conv1</td>\n",
       "      <td>(None, 112, 112, 64)</td>\n",
       "      <td>(None, 112, 112, 128)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.181</td>\n",
       "      <td>6422.528</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>802816</td>\n",
       "      <td>1605632</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>block2_conv2</td>\n",
       "      <td>(None, 112, 112, 128)</td>\n",
       "      <td>(None, 112, 112, 128)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.004</td>\n",
       "      <td>6422.528</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1605632</td>\n",
       "      <td>1605632</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name            input_shape           output_shape  units  filters  \\\n",
       "1  block1_conv1    (None, 224, 224, 3)   (None, 224, 224, 64)   -1.0     64.0   \n",
       "2  block1_conv2   (None, 224, 224, 64)   (None, 224, 224, 64)   -1.0     64.0   \n",
       "3   block1_pool   (None, 224, 224, 64)   (None, 112, 112, 64)   -1.0     -1.0   \n",
       "4  block2_conv1   (None, 112, 112, 64)  (None, 112, 112, 128)   -1.0    128.0   \n",
       "5  block2_conv2  (None, 112, 112, 128)  (None, 112, 112, 128)   -1.0    128.0   \n",
       "\n",
       "  strides  kernel_size  [avg ms]   [mem KB]  activation_linear  \\\n",
       "1  (1, 1)          9.0     2.657  12845.056                  0   \n",
       "2  (1, 1)          9.0    18.123  12845.056                  0   \n",
       "3  (2, 2)         -1.0     3.437   3211.264                  0   \n",
       "4  (1, 1)          9.0     7.181   6422.528                  0   \n",
       "5  (1, 1)          9.0    13.004   6422.528                  0   \n",
       "\n",
       "   activation_relu  activation_softmax  activation_nan  input_size  \\\n",
       "1                1                   0               0      150528   \n",
       "2                1                   0               0     3211264   \n",
       "3                0                   0               1     3211264   \n",
       "4                1                   0               0      802816   \n",
       "5                1                   0               0     1605632   \n",
       "\n",
       "   output_size  stride_size  \n",
       "1      3211264          1.0  \n",
       "2      3211264          1.0  \n",
       "3       802816          4.0  \n",
       "4      1605632          1.0  \n",
       "5      1605632          1.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned = clean(data)\n",
    "\n",
    "cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 17.122787421224206\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>221952</td>\n",
       "      <td>221952</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.236075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78400</td>\n",
       "      <td>78400</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.920930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>221952</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36992</td>\n",
       "      <td>36992</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.882680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>221952</td>\n",
       "      <td>221952</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.236075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.911988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.911988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>78400</td>\n",
       "      <td>78400</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.003876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>235200</td>\n",
       "      <td>78400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36992</td>\n",
       "      <td>36992</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.882680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24576</td>\n",
       "      <td>24576</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.089</td>\n",
       "      <td>0.924709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117600</td>\n",
       "      <td>117600</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.043</td>\n",
       "      <td>1.368286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.911988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>352800</td>\n",
       "      <td>78400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.014532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81920</td>\n",
       "      <td>12288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     units  filters  kernel_size  activation_linear  activation_relu  \\\n",
       "228   -1.0     -1.0         -1.0                  0                0   \n",
       "89    -1.0     -1.0         -1.0                  0                1   \n",
       "197   -1.0    192.0          1.0                  1                0   \n",
       "111   -1.0     -1.0         -1.0                  0                1   \n",
       "164   -1.0     -1.0         -1.0                  0                0   \n",
       "158   -1.0     -1.0         -1.0                  0                0   \n",
       "190   -1.0     -1.0         -1.0                  0                0   \n",
       "212   -1.0     -1.0         -1.0                  0                0   \n",
       "214   -1.0     -1.0         -1.0                  0                1   \n",
       "162   -1.0     -1.0         -1.0                  0                1   \n",
       "78    -1.0     -1.0         -1.0                  0                0   \n",
       "18    -1.0     64.0          1.0                  1                0   \n",
       "117   -1.0     -1.0         -1.0                  0                1   \n",
       "256   -1.0     -1.0         -1.0                  0                1   \n",
       "84    -1.0     -1.0         -1.0                  0                1   \n",
       "208   -1.0     -1.0         -1.0                  0                1   \n",
       "64    -1.0     64.0          1.0                  1                0   \n",
       "210   -1.0    192.0          7.0                  1                0   \n",
       "191   -1.0     -1.0         -1.0                  0                0   \n",
       "268   -1.0    192.0          1.0                  1                0   \n",
       "\n",
       "     activation_softmax  activation_nan  input_size  output_size  stride_size  \\\n",
       "228                   0               1      221952       221952         -1.0   \n",
       "89                    0               0       78400        78400         -1.0   \n",
       "197                   0               0      221952        55488          1.0   \n",
       "111                   0               0       36992        36992         -1.0   \n",
       "164                   0               1      221952       221952         -1.0   \n",
       "158                   0               1       55488        55488         -1.0   \n",
       "190                   0               1       55488        55488         -1.0   \n",
       "212                   0               1       55488        55488         -1.0   \n",
       "214                   0               0       55488        55488         -1.0   \n",
       "162                   0               0       55488        55488         -1.0   \n",
       "78                    0               1       78400        78400         -1.0   \n",
       "18                    0               0      235200        78400          1.0   \n",
       "117                   0               0       36992        36992         -1.0   \n",
       "256                   0               0       24576        24576         -1.0   \n",
       "84                    0               0      117600       117600         -1.0   \n",
       "208                   0               0       55488        55488         -1.0   \n",
       "64                    0               0      352800        78400          1.0   \n",
       "210                   0               0       55488        55488          1.0   \n",
       "191                   0               1       55488        55488         -1.0   \n",
       "268                   0               0       81920        12288          1.0   \n",
       "\n",
       "     avg_ms_actual  avg_ms_pred  \n",
       "228          0.182     0.236075  \n",
       "89           0.683     0.920930  \n",
       "197          0.002     0.002323  \n",
       "111          0.992     0.882680  \n",
       "164          0.272     0.236075  \n",
       "158          0.006     0.005435  \n",
       "190          0.007     0.005435  \n",
       "212          0.006     0.005435  \n",
       "214          0.654     0.911988  \n",
       "162          0.546     0.911988  \n",
       "78           0.005     0.003876  \n",
       "18           0.002     0.002030  \n",
       "117          0.868     0.882680  \n",
       "256          1.089     0.924709  \n",
       "84           1.043     1.368286  \n",
       "208          0.999     0.911988  \n",
       "64           0.002     0.014532  \n",
       "210          0.003     0.002421  \n",
       "191          0.005     0.005435  \n",
       "268          0.002     0.003586  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = cleaned.drop(['name', '[avg ms]', '[mem KB]', 'input_shape', 'output_shape', 'strides'], axis=1)  # Features\n",
    "y = cleaned['[avg ms]']  # Labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train);\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1).sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 307752.0114859972\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>mem_KB_actual</th>\n",
       "      <th>mem_KB_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36992</td>\n",
       "      <td>36992</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>147.968</td>\n",
       "      <td>147.710592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24576</td>\n",
       "      <td>24576</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78400</td>\n",
       "      <td>117600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>15.138816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58800</td>\n",
       "      <td>58800</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>235.200</td>\n",
       "      <td>230.245248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55488</td>\n",
       "      <td>12288</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>46.583680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46240</td>\n",
       "      <td>46240</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117600</td>\n",
       "      <td>117600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.031616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58800</td>\n",
       "      <td>58800</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>352800</td>\n",
       "      <td>78400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.330496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>117600</td>\n",
       "      <td>117600</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.686976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>221952</td>\n",
       "      <td>221952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>887.808</td>\n",
       "      <td>896.394752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>221952</td>\n",
       "      <td>36992</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81920</td>\n",
       "      <td>12288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58800</td>\n",
       "      <td>58800</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     units  filters  kernel_size  activation_linear  activation_relu  \\\n",
       "111   -1.0     -1.0         -1.0                  0                1   \n",
       "291   -1.0    384.0          3.0                  1                0   \n",
       "222   -1.0     -1.0         -1.0                  0                0   \n",
       "68    -1.0     96.0          9.0                  1                0   \n",
       "218   -1.0    192.0          7.0                  1                0   \n",
       "25    -1.0     -1.0         -1.0                  0                1   \n",
       "242   -1.0    192.0          9.0                  1                0   \n",
       "209   -1.0    192.0          7.0                  1                0   \n",
       "178   -1.0    160.0          7.0                  1                0   \n",
       "76    -1.0     96.0          9.0                  1                0   \n",
       "46    -1.0     -1.0         -1.0                  0                0   \n",
       "238   -1.0     -1.0         -1.0                  0                0   \n",
       "230   -1.0     -1.0         -1.0                  0                0   \n",
       "87    -1.0     64.0          1.0                  1                0   \n",
       "200   -1.0    192.0          7.0                  1                0   \n",
       "80    -1.0     -1.0         -1.0                  0                0   \n",
       "119   -1.0     -1.0         -1.0                  0                0   \n",
       "107   -1.0    128.0          1.0                  1                0   \n",
       "268   -1.0    192.0          1.0                  1                0   \n",
       "69    -1.0     -1.0         -1.0                  0                0   \n",
       "\n",
       "     activation_softmax  activation_nan  input_size  output_size  stride_size  \\\n",
       "111                   0               0       36992        36992         -1.0   \n",
       "291                   0               0       24576        24576          1.0   \n",
       "222                   0               1       55488        55488         -1.0   \n",
       "68                    0               0       78400       117600          1.0   \n",
       "218                   0               0       55488        55488          1.0   \n",
       "25                    0               0       58800        58800         -1.0   \n",
       "242                   0               0       55488        12288          4.0   \n",
       "209                   0               0       55488        55488          1.0   \n",
       "178                   0               0       46240        46240          1.0   \n",
       "76                    0               0      117600       117600          1.0   \n",
       "46                    0               1       58800        58800         -1.0   \n",
       "238                   0               1       55488        55488         -1.0   \n",
       "230                   0               1       55488        55488         -1.0   \n",
       "87                    0               0      352800        78400          1.0   \n",
       "200                   0               0       55488        55488          1.0   \n",
       "80                    0               1      117600       117600         -1.0   \n",
       "119                   0               1      221952       221952          1.0   \n",
       "107                   0               0      221952        36992          1.0   \n",
       "268                   0               0       81920        12288          1.0   \n",
       "69                    0               1       58800        58800         -1.0   \n",
       "\n",
       "     mem_KB_actual  mem_KB_pred  \n",
       "111        147.968   147.710592  \n",
       "291          0.000     0.000000  \n",
       "222          0.000     0.000000  \n",
       "68           0.000    15.138816  \n",
       "218          0.000     0.000000  \n",
       "25         235.200   230.245248  \n",
       "242          0.000    46.583680  \n",
       "209          0.000     0.000000  \n",
       "178          0.000     0.000000  \n",
       "76           0.000     2.031616  \n",
       "46           0.000     0.000000  \n",
       "238          0.000     0.000000  \n",
       "230          0.000     0.000000  \n",
       "87           0.000     2.330496  \n",
       "200          0.000     0.000000  \n",
       "80           0.000     2.686976  \n",
       "119        887.808   896.394752  \n",
       "107          0.000     0.000000  \n",
       "268          0.000     0.008192  \n",
       "69           0.000     0.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = cleaned.drop(['name', '[avg ms]', '[mem KB]', 'input_shape', 'output_shape', 'strides'], axis=1)  # Features\n",
    "y = cleaned['[mem KB]']  # Labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train);\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_KB_actual': y_test, 'mem_KB_pred': y_pred})], axis=1).sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.34952883344050234\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>78400</td>\n",
       "      <td>78400</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>221952</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100352</td>\n",
       "      <td>100352</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.547</td>\n",
       "      <td>5.886958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12288</td>\n",
       "      <td>12288</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.287</td>\n",
       "      <td>0.829712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28672</td>\n",
       "      <td>28672</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.006932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>131072</td>\n",
       "      <td>131072</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.484421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>78400</td>\n",
       "      <td>78400</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58800</td>\n",
       "      <td>78400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>401408</td>\n",
       "      <td>802816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.049</td>\n",
       "      <td>5.958100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39200</td>\n",
       "      <td>39200</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.799501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     units  filters  kernel_size  activation_linear  activation_relu  \\\n",
       "56    -1.0     -1.0         -1.0                  0                0   \n",
       "155   -1.0    192.0          1.0                  1                0   \n",
       "17    -1.0    512.0          9.0                  0                1   \n",
       "309   -1.0     -1.0         -1.0                  0                1   \n",
       "250   -1.0     -1.0         -1.0                  0                0   \n",
       "293   -1.0     -1.0         -1.0                  0                0   \n",
       "42    -1.0     -1.0         -1.0                  0                0   \n",
       "52    -1.0     64.0         25.0                  1                0   \n",
       "7     -1.0    256.0          9.0                  0                1   \n",
       "39    -1.0     -1.0         -1.0                  0                1   \n",
       "\n",
       "     activation_softmax  activation_nan  input_size  output_size  stride_size  \\\n",
       "56                    0               1       78400        78400         -1.0   \n",
       "155                   0               0      221952        55488          1.0   \n",
       "17                    0               0      100352       100352          1.0   \n",
       "309                   0               0       12288        12288         -1.0   \n",
       "250                   0               1       28672        28672         -1.0   \n",
       "293                   0               1      131072       131072          1.0   \n",
       "42                    0               1       78400        78400         -1.0   \n",
       "52                    0               0       58800        78400          1.0   \n",
       "7                     0               0      401408       802816          1.0   \n",
       "39                    0               0       39200        39200         -1.0   \n",
       "\n",
       "     avg_ms_actual  avg_ms_pred  \n",
       "56           0.004     0.004020  \n",
       "155          0.002     0.002239  \n",
       "17           4.547     5.886958  \n",
       "309          1.287     0.829712  \n",
       "250          0.005     0.006932  \n",
       "293          0.762     0.484421  \n",
       "42           0.003     0.004020  \n",
       "52           0.002     0.004722  \n",
       "7            7.049     5.958100  \n",
       "39           0.434     0.799501  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AVG MS RF\n",
    "rf, X_test, y_test = rf_regression_model(cleaned, '[avg ms]')\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "cnn_ms_rf_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 71955.01628587676\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>mem_kb_actual</th>\n",
       "      <th>mem_kb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>221952</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>268203</td>\n",
       "      <td>710432</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>376.104768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>221952</td>\n",
       "      <td>221952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>887.808</td>\n",
       "      <td>889.768704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117600</td>\n",
       "      <td>117600</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>470.400</td>\n",
       "      <td>463.701504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100352</td>\n",
       "      <td>25088</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100.352</td>\n",
       "      <td>117.952768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1382976</td>\n",
       "      <td>341056</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1364.224</td>\n",
       "      <td>1513.208000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>221952</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>235200</td>\n",
       "      <td>58800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24576</td>\n",
       "      <td>24576</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>98.304</td>\n",
       "      <td>98.304000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     units  filters  kernel_size  activation_linear  activation_relu  \\\n",
       "229   -1.0    192.0          1.0                  1                0   \n",
       "1     -1.0     32.0          9.0                  1                0   \n",
       "151   -1.0     -1.0         -1.0                  0                0   \n",
       "92    -1.0     -1.0         -1.0                  0                1   \n",
       "18    -1.0     -1.0         -1.0                  0                0   \n",
       "10    -1.0     -1.0         -1.0                  0                0   \n",
       "123   -1.0    192.0          1.0                  1                0   \n",
       "21    -1.0     48.0          1.0                  1                0   \n",
       "232   -1.0    192.0          7.0                  1                0   \n",
       "288   -1.0     -1.0         -1.0                  0                1   \n",
       "\n",
       "     activation_softmax  activation_nan  input_size  output_size  stride_size  \\\n",
       "229                   0               0      221952        55488          1.0   \n",
       "1                     0               0      268203       710432          4.0   \n",
       "151                   0               1      221952       221952          1.0   \n",
       "92                    0               0      117600       117600         -1.0   \n",
       "18                    0               1      100352        25088          4.0   \n",
       "10                    0               1     1382976       341056          4.0   \n",
       "123                   0               0      221952        55488          1.0   \n",
       "21                    0               0      235200        58800          1.0   \n",
       "232                   0               0       55488        55488          1.0   \n",
       "288                   0               0       24576        24576         -1.0   \n",
       "\n",
       "     mem_kb_actual  mem_kb_pred  \n",
       "229          0.000     0.000000  \n",
       "1            0.000   376.104768  \n",
       "151        887.808   889.768704  \n",
       "92         470.400   463.701504  \n",
       "18         100.352   117.952768  \n",
       "10        1364.224  1513.208000  \n",
       "123          0.000     0.000000  \n",
       "21           0.000     0.000000  \n",
       "232          0.000     0.000000  \n",
       "288         98.304    98.304000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MEM KB RF\n",
    "rf, X_test, y_test = rf_regression_model(cleaned, '[mem KB]')\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "cnn_mem_rf_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_kb_actual': y_test, 'mem_kb_pred': y_pred})], axis=1).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2.304815746815876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>221952</td>\n",
       "      <td>46240</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.421680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>78400</td>\n",
       "      <td>78400</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.268668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.290258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12288</td>\n",
       "      <td>12288</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.287</td>\n",
       "      <td>0.757708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>221952</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.343088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.989789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117600</td>\n",
       "      <td>117600</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.290</td>\n",
       "      <td>1.365286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78400</td>\n",
       "      <td>78400</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.925</td>\n",
       "      <td>0.827638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58800</td>\n",
       "      <td>58800</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.533482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.989789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     units  filters  kernel_size  activation_linear  activation_relu  \\\n",
       "139   -1.0    160.0          1.0                  1                0   \n",
       "55    -1.0     -1.0         -1.0                  0                0   \n",
       "125   -1.0     -1.0         -1.0                  0                0   \n",
       "309   -1.0     -1.0         -1.0                  0                1   \n",
       "216   -1.0    192.0          1.0                  1                0   \n",
       "129   -1.0     -1.0         -1.0                  0                1   \n",
       "49    -1.0     -1.0         -1.0                  0                1   \n",
       "83    -1.0     -1.0         -1.0                  0                1   \n",
       "25    -1.0     -1.0         -1.0                  0                1   \n",
       "239   -1.0     -1.0         -1.0                  0                1   \n",
       "\n",
       "     activation_softmax  activation_nan  input_size  output_size  stride_size  \\\n",
       "139                   0               0      221952        46240          1.0   \n",
       "55                    0               1       78400        78400         -1.0   \n",
       "125                   0               1       55488        55488         -1.0   \n",
       "309                   0               0       12288        12288         -1.0   \n",
       "216                   0               0      221952        55488          1.0   \n",
       "129                   0               0       55488        55488         -1.0   \n",
       "49                    0               0      117600       117600         -1.0   \n",
       "83                    0               0       78400        78400         -1.0   \n",
       "25                    0               0       58800        58800         -1.0   \n",
       "239                   0               0       55488        55488         -1.0   \n",
       "\n",
       "     avg_ms_actual  avg_ms_pred  \n",
       "139          0.002     0.421680  \n",
       "55           0.005     0.268668  \n",
       "125          0.003     0.290258  \n",
       "309          1.287     0.757708  \n",
       "216          0.002     0.343088  \n",
       "129          0.708     0.989789  \n",
       "49           1.290     1.365286  \n",
       "83           1.925     0.827638  \n",
       "25           0.450     0.533482  \n",
       "239          0.671     0.989789  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AVG MS stacked\n",
    "rf, X_test, y_test = stacked_regression_model(cleaned, '[avg ms]')\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "cnn_ms_stacked_1_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1094164.5002207097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>mem_kb_actual</th>\n",
       "      <th>mem_kb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78400</td>\n",
       "      <td>117600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>22.071346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>221952</td>\n",
       "      <td>46240</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-2.551156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221.952</td>\n",
       "      <td>274.605235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39200</td>\n",
       "      <td>39200</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>156.800</td>\n",
       "      <td>211.032893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>117600</td>\n",
       "      <td>117600</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>98.741279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24576</td>\n",
       "      <td>24576</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>98.304</td>\n",
       "      <td>163.962149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117600</td>\n",
       "      <td>117600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>28.497215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>221952</td>\n",
       "      <td>221952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>887.808</td>\n",
       "      <td>784.479304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>352800</td>\n",
       "      <td>352800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1411.200</td>\n",
       "      <td>1210.385057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1605632</td>\n",
       "      <td>401408</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1605.632</td>\n",
       "      <td>1459.475633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     units  filters  kernel_size  activation_linear  activation_relu  \\\n",
       "68    -1.0     96.0          9.0                  1                0   \n",
       "171   -1.0    160.0          1.0                  1                0   \n",
       "214   -1.0     -1.0         -1.0                  0                1   \n",
       "39    -1.0     -1.0         -1.0                  0                1   \n",
       "80    -1.0     -1.0         -1.0                  0                0   \n",
       "303   -1.0     -1.0         -1.0                  0                1   \n",
       "76    -1.0     96.0          9.0                  1                0   \n",
       "183   -1.0     -1.0         -1.0                  0                0   \n",
       "73    -1.0     -1.0         -1.0                  0                0   \n",
       "6     -1.0     -1.0         -1.0                  0                0   \n",
       "\n",
       "     activation_softmax  activation_nan  input_size  output_size  stride_size  \\\n",
       "68                    0               0       78400       117600          1.0   \n",
       "171                   0               0      221952        46240          1.0   \n",
       "214                   0               0       55488        55488         -1.0   \n",
       "39                    0               0       39200        39200         -1.0   \n",
       "80                    0               1      117600       117600         -1.0   \n",
       "303                   0               0       24576        24576         -1.0   \n",
       "76                    0               0      117600       117600          1.0   \n",
       "183                   0               1      221952       221952          1.0   \n",
       "73                    0               1      352800       352800          1.0   \n",
       "6                     0               1     1605632       401408          4.0   \n",
       "\n",
       "     mem_kb_actual  mem_kb_pred  \n",
       "68           0.000    22.071346  \n",
       "171          0.000    -2.551156  \n",
       "214        221.952   274.605235  \n",
       "39         156.800   211.032893  \n",
       "80           0.000    98.741279  \n",
       "303         98.304   163.962149  \n",
       "76           0.000    28.497215  \n",
       "183        887.808   784.479304  \n",
       "73        1411.200  1210.385057  \n",
       "6         1605.632  1459.475633  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AVG MEM stacked\n",
    "rf, X_test, y_test = stacked_regression_model(cleaned, '[mem KB]')\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "cnn_mem_stacked_1_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_kb_actual': y_test, 'mem_kb_pred': y_pred})], axis=1).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2.3735852600893597\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>426320</td>\n",
       "      <td>967872</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>2.326231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24576</td>\n",
       "      <td>24576</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.160214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>221952</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.108440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.073</td>\n",
       "      <td>1.477779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.612313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     units  filters  kernel_size  activation_linear  activation_relu  \\\n",
       "14    -1.0    192.0          9.0                  1                0   \n",
       "298   -1.0     -1.0         -1.0                  0                0   \n",
       "155   -1.0    192.0          1.0                  1                0   \n",
       "192   -1.0     -1.0         -1.0                  0                1   \n",
       "217   -1.0    192.0          7.0                  1                0   \n",
       "\n",
       "     activation_softmax  activation_nan  input_size  output_size  stride_size  \\\n",
       "14                    0               0      426320       967872          1.0   \n",
       "298                   0               1       24576        24576         -1.0   \n",
       "155                   0               0      221952        55488          1.0   \n",
       "192                   0               0       55488        55488         -1.0   \n",
       "217                   0               0       55488        55488          1.0   \n",
       "\n",
       "     avg_ms_actual  avg_ms_pred  \n",
       "14           0.002     2.326231  \n",
       "298          0.008     0.160214  \n",
       "155          0.002     0.108440  \n",
       "192          1.073     1.477779  \n",
       "217          0.003     0.612313  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lstm stacked avg ms\n",
    "sr2, X_test, y_test = stacked_regression_model_2(cleaned, '[avg ms]')\n",
    "\n",
    "y_pred = sr2.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "cnn_ms_stacked_2_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 8.219082766282362e+17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>mem_kb_actual</th>\n",
       "      <th>mem_kb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.061589e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117600</td>\n",
       "      <td>117600</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>470.400</td>\n",
       "      <td>9.061590e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12288</td>\n",
       "      <td>12288</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.061588e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100352</td>\n",
       "      <td>100352</td>\n",
       "      <td>1.0</td>\n",
       "      <td>401.408</td>\n",
       "      <td>9.061575e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58800</td>\n",
       "      <td>58800</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.061589e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     units  filters  kernel_size  activation_linear  activation_relu  \\\n",
       "222   -1.0     -1.0         -1.0                  0                0   \n",
       "84    -1.0     -1.0         -1.0                  0                1   \n",
       "274   -1.0     -1.0         -1.0                  0                0   \n",
       "16    -1.0    512.0          9.0                  0                1   \n",
       "23    -1.0     -1.0         -1.0                  0                0   \n",
       "\n",
       "     activation_softmax  activation_nan  input_size  output_size  stride_size  \\\n",
       "222                   0               1       55488        55488         -1.0   \n",
       "84                    0               0      117600       117600         -1.0   \n",
       "274                   0               1       12288        12288         -1.0   \n",
       "16                    0               0      100352       100352          1.0   \n",
       "23                    0               1       58800        58800         -1.0   \n",
       "\n",
       "     mem_kb_actual   mem_kb_pred  \n",
       "222          0.000  9.061589e+08  \n",
       "84         470.400  9.061590e+08  \n",
       "274          0.000  9.061588e+08  \n",
       "16         401.408  9.061575e+08  \n",
       "23           0.000  9.061589e+08  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lstm stacked mem\n",
    "sr2, X_test, y_test = stacked_regression_model_2(cleaned, '[mem KB]')\n",
    "\n",
    "y_pred = sr2.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "cnn_mem_stacked_2_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_kb_actual': y_test, 'mem_kb_pred': y_pred})], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/brian/anaconda/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/brian/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Retrieving saved model and benchmark results.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[node type]</th>\n",
       "      <th>[start]</th>\n",
       "      <th>[first]</th>\n",
       "      <th>[avg ms]</th>\n",
       "      <th>[%]</th>\n",
       "      <th>[cdf%]</th>\n",
       "      <th>[mem KB]</th>\n",
       "      <th>[times called]</th>\n",
       "      <th>[Name]</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Enter</td>\n",
       "      <td>171.058</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002%</td>\n",
       "      <td>9.435%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm5/while/TensorArrayReadV3/Enter_1</td>\n",
       "      <td>lstm5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>Const</td>\n",
       "      <td>-24.271</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001%</td>\n",
       "      <td>75.558%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm2/kernel</td>\n",
       "      <td>lstm2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>Switch</td>\n",
       "      <td>-0.856</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.341%</td>\n",
       "      <td>88.465%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>251</td>\n",
       "      <td>lstm1/while/Switch_2</td>\n",
       "      <td>lstm1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>Enter</td>\n",
       "      <td>-24.129</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001%</td>\n",
       "      <td>75.611%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm3/while/Enter_1</td>\n",
       "      <td>lstm3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>Range</td>\n",
       "      <td>-23.890</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.005%</td>\n",
       "      <td>84.005%</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm1/TensorArrayUnstack/range</td>\n",
       "      <td>lstm1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Const</td>\n",
       "      <td>190.609</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.229%</td>\n",
       "      <td>15.452%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>250</td>\n",
       "      <td>ConstantFolding/lstm5/while/split_1-folded-1</td>\n",
       "      <td>ConstantFolding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Enter</td>\n",
       "      <td>120.857</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003%</td>\n",
       "      <td>34.794%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm4/while/TensorArrayReadV3/Enter</td>\n",
       "      <td>lstm4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Mul</td>\n",
       "      <td>46.095</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.221%</td>\n",
       "      <td>62.502%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>250</td>\n",
       "      <td>lstm2/while/Mul</td>\n",
       "      <td>lstm2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Const</td>\n",
       "      <td>-24.330</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001%</td>\n",
       "      <td>75.544%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm5/bias</td>\n",
       "      <td>lstm5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Less</td>\n",
       "      <td>190.664</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.338%</td>\n",
       "      <td>17.811%</td>\n",
       "      <td>0.001</td>\n",
       "      <td>251</td>\n",
       "      <td>lstm5/while/Less_1</td>\n",
       "      <td>lstm5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>Identity</td>\n",
       "      <td>-5.152</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.242%</td>\n",
       "      <td>85.160%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>250</td>\n",
       "      <td>lstm1/while/Identity</td>\n",
       "      <td>lstm1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Const</td>\n",
       "      <td>41.708</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.233%</td>\n",
       "      <td>74.002%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>250</td>\n",
       "      <td>lstm2/while/strided_slice_1</td>\n",
       "      <td>lstm2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>NextIteration</td>\n",
       "      <td>91.052</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.420%</td>\n",
       "      <td>52.040%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>250</td>\n",
       "      <td>lstm3/while/NextIteration</td>\n",
       "      <td>lstm3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Const</td>\n",
       "      <td>-24.249</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001%</td>\n",
       "      <td>75.563%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm5/strided_slice_7/stack</td>\n",
       "      <td>lstm5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Merge</td>\n",
       "      <td>144.830</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.437%</td>\n",
       "      <td>34.792%</td>\n",
       "      <td>0.004</td>\n",
       "      <td>251</td>\n",
       "      <td>lstm4/while/Merge_3</td>\n",
       "      <td>lstm4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  [node type]  [start]  [first]  [avg ms]       [%]    [cdf%]  \\\n",
       "39                      Enter  171.058    0.006     0.004    0.002%    9.435%   \n",
       "380                     Const  -24.271    0.002     0.003    0.001%   75.558%   \n",
       "485                    Switch   -0.856    0.008     0.003    0.341%   88.465%   \n",
       "417                     Enter  -24.129    0.003     0.003    0.001%   75.611%   \n",
       "460                     Range  -23.890    0.045     0.013    0.005%   84.005%   \n",
       "63                      Const  190.609    0.003     0.002    0.229%   15.452%   \n",
       "151                     Enter  120.857    0.023     0.006    0.003%   34.794%   \n",
       "288                       Mul   46.095    0.006     0.002    0.221%   62.502%   \n",
       "362                     Const  -24.330    0.003     0.002    0.001%   75.544%   \n",
       "72                       Less  190.664    0.008     0.003    0.338%   17.811%   \n",
       "465                  Identity   -5.152    0.006     0.002    0.242%   85.160%   \n",
       "340                     Const   41.708    0.005     0.002    0.233%   74.002%   \n",
       "238             NextIteration   91.052    0.006     0.004    0.420%   52.040%   \n",
       "387                     Const  -24.249    0.002     0.002    0.001%   75.563%   \n",
       "150                     Merge  144.830    0.025     0.004    0.437%   34.792%   \n",
       "\n",
       "     [mem KB]  [times called]                                        [Name]  \\\n",
       "39      0.000               1         lstm5/while/TensorArrayReadV3/Enter_1   \n",
       "380     0.000               1                                  lstm2/kernel   \n",
       "485     0.000             251                          lstm1/while/Switch_2   \n",
       "417     0.000               1                           lstm3/while/Enter_1   \n",
       "460     1.000               1                lstm1/TensorArrayUnstack/range   \n",
       "63      0.000             250  ConstantFolding/lstm5/while/split_1-folded-1   \n",
       "151     0.000               1           lstm4/while/TensorArrayReadV3/Enter   \n",
       "288     0.000             250                               lstm2/while/Mul   \n",
       "362     0.000               1                                    lstm5/bias   \n",
       "72      0.001             251                            lstm5/while/Less_1   \n",
       "465     0.000             250                          lstm1/while/Identity   \n",
       "340     0.000             250                   lstm2/while/strided_slice_1   \n",
       "238     0.000             250                     lstm3/while/NextIteration   \n",
       "387     0.000               1                   lstm5/strided_slice_7/stack   \n",
       "150     0.004             251                           lstm4/while/Merge_3   \n",
       "\n",
       "                name  \n",
       "39             lstm5  \n",
       "380            lstm2  \n",
       "485            lstm1  \n",
       "417            lstm3  \n",
       "460            lstm1  \n",
       "63   ConstantFolding  \n",
       "151            lstm4  \n",
       "288            lstm2  \n",
       "362            lstm5  \n",
       "72             lstm5  \n",
       "465            lstm1  \n",
       "340            lstm2  \n",
       "238            lstm3  \n",
       "387            lstm5  \n",
       "150            lstm4  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lstm.summary()\n",
    "\n",
    "tf.keras.backend.clear_session() # IMPORTANT for layer names to match up.\n",
    "\n",
    "lstm = create_lstm()\n",
    "\n",
    "# tf.keras.backend.set_learning_phase(0)\n",
    "lstm_benchmark = benchmark_model(lstm)\n",
    "lstm_benchmark.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_features = get_layer_features(lstm)\n",
    "lstm_df = join_benchmark(lstm_features, lstm_benchmark)\n",
    "cleaned_lstm = clean(lstm_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0019752402566664364\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32000</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.896243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.215739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8000</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.901940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   units  filters  kernel_size  activation_relu  activation_sigmoid  \\\n",
       "7   48.0     -1.0         -1.0                0                   0   \n",
       "1   -1.0     32.0          3.0                1                   0   \n",
       "5   64.0     -1.0         -1.0                0                   0   \n",
       "\n",
       "   activation_tanh  activation_nan  input_size  output_size  stride_size  \\\n",
       "7                1               0       32000           48         -1.0   \n",
       "1                0               0       16000        16000          1.0   \n",
       "5                1               0        8000        16000         -1.0   \n",
       "\n",
       "   avg_ms_actual  avg_ms_pred  \n",
       "7          0.941     0.896243  \n",
       "1          0.166     0.215739  \n",
       "5          0.940     0.901940  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf, X_test, y_test = rf_regression_model(cleaned_lstm, '[avg ms]')\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 224.08000590825523\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>mem_kb_actual</th>\n",
       "      <th>mem_kb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32000</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>26.336732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>39.488188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8000</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>38.272040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   units  filters  kernel_size  activation_relu  activation_sigmoid  \\\n",
       "7   48.0     -1.0         -1.0                0                   0   \n",
       "1   -1.0     32.0          3.0                1                   0   \n",
       "5   64.0     -1.0         -1.0                0                   0   \n",
       "\n",
       "   activation_tanh  activation_nan  input_size  output_size  stride_size  \\\n",
       "7                1               0       32000           48         -1.0   \n",
       "1                0               0       16000        16000          1.0   \n",
       "5                1               0        8000        16000         -1.0   \n",
       "\n",
       "   mem_kb_actual  mem_kb_pred  \n",
       "7           32.0    26.336732  \n",
       "1           64.0    39.488188  \n",
       "5           32.0    38.272040  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf, X_test, y_test = rf_regression_model(cleaned_lstm, '[mem KB]')\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_kb_actual': y_test, 'mem_kb_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2654940543791902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166</td>\n",
       "      <td>-0.280315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.781785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.997358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   units  filters  kernel_size  activation_relu  activation_sigmoid  \\\n",
       "1   -1.0     32.0          3.0                1                   0   \n",
       "8    1.0     -1.0         -1.0                0                   1   \n",
       "4   32.0     -1.0         -1.0                0                   0   \n",
       "\n",
       "   activation_tanh  activation_nan  input_size  output_size  stride_size  \\\n",
       "1                0               0       16000        16000          1.0   \n",
       "8                0               0          48            1         -1.0   \n",
       "4                1               0        2500         8000         -1.0   \n",
       "\n",
       "   avg_ms_actual  avg_ms_pred  \n",
       "1          0.166    -0.280315  \n",
       "8          0.011     0.781785  \n",
       "4          0.941     0.997358  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lstm stacked avg ms\n",
    "rf, X_test, y_test = stacked_regression_model(cleaned_lstm, '[avg ms]')\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1953.5895497159127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>mem_kb_actual</th>\n",
       "      <th>mem_kb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32000</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.347249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>128.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16000</td>\n",
       "      <td>32000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>107.434087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8000</td>\n",
       "      <td>2500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>36.244122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   units  filters  kernel_size  activation_relu  activation_sigmoid  \\\n",
       "7   48.0     -1.0         -1.0                0                   0   \n",
       "6  128.0     -1.0         -1.0                0                   0   \n",
       "3   10.0     -1.0         -1.0                0                   0   \n",
       "\n",
       "   activation_tanh  activation_nan  input_size  output_size  stride_size  \\\n",
       "7                1               0       32000           48         -1.0   \n",
       "6                1               0       16000        32000         -1.0   \n",
       "3                1               0        8000         2500         -1.0   \n",
       "\n",
       "   mem_kb_actual  mem_kb_pred  \n",
       "7           32.0    44.347249  \n",
       "6           32.0   107.434087  \n",
       "3           32.0    36.244122  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lstm stacked mem\n",
    "rf, X_test, y_test = stacked_regression_model(cleaned_lstm, '[mem KB]')\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_kb_actual': y_test, 'mem_kb_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1294695050451215.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8000</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.940</td>\n",
       "      <td>3.598196e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8000</td>\n",
       "      <td>2500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.952</td>\n",
       "      <td>3.597906e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.941</td>\n",
       "      <td>3.598459e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   units  filters  kernel_size  activation_relu  activation_sigmoid  \\\n",
       "5   64.0     -1.0         -1.0                0                   0   \n",
       "3   10.0     -1.0         -1.0                0                   0   \n",
       "4   32.0     -1.0         -1.0                0                   0   \n",
       "\n",
       "   activation_tanh  activation_nan  input_size  output_size  stride_size  \\\n",
       "5                1               0        8000        16000         -1.0   \n",
       "3                1               0        8000         2500         -1.0   \n",
       "4                1               0        2500         8000         -1.0   \n",
       "\n",
       "   avg_ms_actual   avg_ms_pred  \n",
       "5          0.940  3.598196e+07  \n",
       "3          0.952  3.597906e+07  \n",
       "4          0.941  3.598459e+07  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lstm stacked avg ms\n",
    "rf, X_test, y_test = stacked_regression_model_2(cleaned_lstm, '[avg ms]')\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 495.63810920509536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>mem_kb_actual</th>\n",
       "      <th>mem_kb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>49.625047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>49.538990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8000</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>63.099055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   units  filters  kernel_size  activation_relu  activation_sigmoid  \\\n",
       "4   32.0     -1.0         -1.0                0                   0   \n",
       "1   -1.0     32.0          3.0                1                   0   \n",
       "5   64.0     -1.0         -1.0                0                   0   \n",
       "\n",
       "   activation_tanh  activation_nan  input_size  output_size  stride_size  \\\n",
       "4                1               0        2500         8000         -1.0   \n",
       "1                0               0       16000        16000          1.0   \n",
       "5                1               0        8000        16000         -1.0   \n",
       "\n",
       "   mem_kb_actual  mem_kb_pred  \n",
       "4           32.0    49.625047  \n",
       "1           64.0    49.538990  \n",
       "5           32.0    63.099055  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lstm stacked mem\n",
    "rf, X_test, y_test = stacked_regression_model_2(cleaned_lstm, '[mem KB]')\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_kb_actual': y_test, 'mem_kb_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving saved model and benchmark results.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[node type]</th>\n",
       "      <th>[start]</th>\n",
       "      <th>[first]</th>\n",
       "      <th>[avg ms]</th>\n",
       "      <th>[%]</th>\n",
       "      <th>[cdf%]</th>\n",
       "      <th>[mem KB]</th>\n",
       "      <th>[times called]</th>\n",
       "      <th>[Name]</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Const</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.377%</td>\n",
       "      <td>2.587%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm1/strided_slice/stack</td>\n",
       "      <td>lstm1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Const</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.556%</td>\n",
       "      <td>35.641%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>ConstantFolding/lstm1/while/split-folded-0</td>\n",
       "      <td>ConstantFolding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Enter</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.757%</td>\n",
       "      <td>67.111%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm1/while/TensorArrayReadV3/Enter_1</td>\n",
       "      <td>lstm1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Enter</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.415%</td>\n",
       "      <td>6.624%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm1/while/Enter</td>\n",
       "      <td>lstm1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>MatMul</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.012</td>\n",
       "      <td>2.926%</td>\n",
       "      <td>81.040%</td>\n",
       "      <td>1.024</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm1/while/MatMul_3</td>\n",
       "      <td>lstm1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 [node type]  [start]  [first]  [avg ms]       [%]    [cdf%]  \\\n",
       "5                      Const   -0.108    0.002     0.002    0.377%    2.587%   \n",
       "47                     Const    0.052    0.003     0.002    0.556%   35.641%   \n",
       "59                     Enter    0.007    0.009     0.003    0.757%   67.111%   \n",
       "14                     Enter   -0.083    0.002     0.002    0.415%    6.624%   \n",
       "66                    MatMul    0.041    0.016     0.012    2.926%   81.040%   \n",
       "\n",
       "    [mem KB]  [times called]                                      [Name]  \\\n",
       "5      0.000               1                   lstm1/strided_slice/stack   \n",
       "47     0.000               1  ConstantFolding/lstm1/while/split-folded-0   \n",
       "59     0.000               1       lstm1/while/TensorArrayReadV3/Enter_1   \n",
       "14     0.000               1                           lstm1/while/Enter   \n",
       "66     1.024               1                        lstm1/while/MatMul_3   \n",
       "\n",
       "               name  \n",
       "5             lstm1  \n",
       "47  ConstantFolding  \n",
       "59            lstm1  \n",
       "14            lstm1  \n",
       "66            lstm1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lstm.summary()\n",
    "\n",
    "tf.keras.backend.clear_session() # IMPORTANT for layer names to match up.\n",
    "\n",
    "enc, dec = create_seq2seq()\n",
    "\n",
    "# tf.keras.backend.set_learning_phase(0)\n",
    "enc_benchmark = benchmark_model(enc, '../tensorflow/bazel-bin/tensorflow/tools/benchmark/benchmark_model --graph=encoder.pbtxt --input_layer=\"input_1:0\" --input_layer_shape=\"1,1,71\" --output_layer=\"lstm1/while/Exit_2:0\"')\n",
    "enc_benchmark.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving saved model and benchmark results.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[node type]</th>\n",
       "      <th>[start]</th>\n",
       "      <th>[first]</th>\n",
       "      <th>[avg ms]</th>\n",
       "      <th>[%]</th>\n",
       "      <th>[cdf%]</th>\n",
       "      <th>[mem KB]</th>\n",
       "      <th>[times called]</th>\n",
       "      <th>[Name]</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Minimum</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.612%</td>\n",
       "      <td>82.161%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm2_1/while/clip_by_value_1/Minimum</td>\n",
       "      <td>lstm2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Const</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.555%</td>\n",
       "      <td>0.943%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm2/kernel</td>\n",
       "      <td>lstm2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Const</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.247%</td>\n",
       "      <td>2.685%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm2_1/TensorArrayUnstack/strided_slice/stack_1</td>\n",
       "      <td>lstm2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Prod</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.358%</td>\n",
       "      <td>98.355%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>dense1_1/Tensordot/Prod_1</td>\n",
       "      <td>dense1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Const</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.411%</td>\n",
       "      <td>27.194%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm2_1/while/strided_slice_1</td>\n",
       "      <td>lstm2_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  [node type]  [start]  [first]  [avg ms]       [%]    [cdf%]  \\\n",
       "91                    Minimum    0.130    0.010     0.004    0.612%   82.161%   \n",
       "1                       Const   -0.121    0.009     0.004    0.555%    0.943%   \n",
       "8                       Const   -0.101    0.002     0.002    0.247%    2.685%   \n",
       "118                      Prod    0.271    0.002     0.002    0.358%   98.355%   \n",
       "49                      Const    0.044    0.003     0.003    0.411%   27.194%   \n",
       "\n",
       "     [mem KB]  [times called]  \\\n",
       "91        0.0               1   \n",
       "1         0.0               1   \n",
       "8         0.0               1   \n",
       "118       0.0               1   \n",
       "49        0.0               1   \n",
       "\n",
       "                                               [Name]      name  \n",
       "91              lstm2_1/while/clip_by_value_1/Minimum   lstm2_1  \n",
       "1                                        lstm2/kernel     lstm2  \n",
       "8    lstm2_1/TensorArrayUnstack/strided_slice/stack_1   lstm2_1  \n",
       "118                         dense1_1/Tensordot/Prod_1  dense1_1  \n",
       "49                      lstm2_1/while/strided_slice_1   lstm2_1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_benchmark = benchmark_model(dec, '../tensorflow/bazel-bin/tensorflow/tools/benchmark/benchmark_model --graph=decoder.pbtxt --input_layer=\"input_2:0,input_3:0,input_4:0\" --input_layer_shape=\"1,1,93:1,256:1,256\" --input_layer_type=float,float,float --output_layer=\"dense1_1/truediv:0\"')\n",
    "dec_benchmark.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq2seq_benchmark = pd.concat([enc_benchmark, dec_benchmark])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc_features = get_layer_features(enc)\n",
    "dec_features = get_layer_features(dec)\n",
    "seq2seq_features = pd.concat([enc_features, dec_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq2seq_df = join_benchmark(seq2seq_features, seq2seq_benchmark)\n",
    "cleaned_seq2seq = clean(seq2seq_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[avg ms]</th>\n",
       "      <th>[mem KB]</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>filters</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>input_size</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>name</th>\n",
       "      <th>output_shape</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>strides</th>\n",
       "      <th>units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166</td>\n",
       "      <td>64.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>(None, 500, 32)</td>\n",
       "      <td>16000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>conv1d</td>\n",
       "      <td>(None, 500, 32)</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(None, 48)</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>dense</td>\n",
       "      <td>(None, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.033</td>\n",
       "      <td>64.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(None, 500)</td>\n",
       "      <td>500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>embedding</td>\n",
       "      <td>(None, 500, 32)</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039</td>\n",
       "      <td>32.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(None, 500, 32)</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>max_pooling1d</td>\n",
       "      <td>(None, 250, 32)</td>\n",
       "      <td>8000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>(2,)</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.941</td>\n",
       "      <td>32.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(None, 250, 10)</td>\n",
       "      <td>2500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>lstm2</td>\n",
       "      <td>(None, 250, 32)</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.965</td>\n",
       "      <td>32.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(None, 250, 64)</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>lstm4</td>\n",
       "      <td>(None, 250, 128)</td>\n",
       "      <td>32000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.952</td>\n",
       "      <td>32.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(None, 250, 32)</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>lstm1</td>\n",
       "      <td>(None, 250, 10)</td>\n",
       "      <td>2500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.940</td>\n",
       "      <td>32.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(None, 250, 32)</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>lstm3</td>\n",
       "      <td>(None, 250, 64)</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.941</td>\n",
       "      <td>32.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(None, 250, 128)</td>\n",
       "      <td>32000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>lstm5</td>\n",
       "      <td>(None, 48)</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.382</td>\n",
       "      <td>1.024</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(None, None, 71)</td>\n",
       "      <td>71</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>lstm1</td>\n",
       "      <td>[(None, 256), (None, 256), (None, 256)]</td>\n",
       "      <td>768</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   [avg ms]  [mem KB]  activation_nan  activation_relu  activation_sigmoid  \\\n",
       "1     0.166    64.000               0              1.0                 0.0   \n",
       "8     0.011     0.004               0              0.0                 1.0   \n",
       "0     0.033    64.000               1              0.0                 0.0   \n",
       "2     0.039    32.000               1              0.0                 0.0   \n",
       "4     0.941    32.000               0              0.0                 0.0   \n",
       "6     0.965    32.000               0              0.0                 0.0   \n",
       "3     0.952    32.000               0              0.0                 0.0   \n",
       "5     0.940    32.000               0              0.0                 0.0   \n",
       "7     0.941    32.000               0              0.0                 0.0   \n",
       "1     0.382     1.024               0              0.0                 0.0   \n",
       "\n",
       "   activation_tanh  filters       input_shape  input_size  kernel_size  \\\n",
       "1                0     32.0   (None, 500, 32)       16000          3.0   \n",
       "8                0     -1.0        (None, 48)          48         -1.0   \n",
       "0                0     -1.0       (None, 500)         500         -1.0   \n",
       "2                0     -1.0   (None, 500, 32)       16000         -1.0   \n",
       "4                1     -1.0   (None, 250, 10)        2500         -1.0   \n",
       "6                1     -1.0   (None, 250, 64)       16000         -1.0   \n",
       "3                1     -1.0   (None, 250, 32)        8000         -1.0   \n",
       "5                1     -1.0   (None, 250, 32)        8000         -1.0   \n",
       "7                1     -1.0  (None, 250, 128)       32000         -1.0   \n",
       "1                1     -1.0  (None, None, 71)          71         -1.0   \n",
       "\n",
       "            name                             output_shape  output_size  \\\n",
       "1         conv1d                          (None, 500, 32)        16000   \n",
       "8          dense                                (None, 1)            1   \n",
       "0      embedding                          (None, 500, 32)        16000   \n",
       "2  max_pooling1d                          (None, 250, 32)         8000   \n",
       "4          lstm2                          (None, 250, 32)         8000   \n",
       "6          lstm4                         (None, 250, 128)        32000   \n",
       "3          lstm1                          (None, 250, 10)         2500   \n",
       "5          lstm3                          (None, 250, 64)        16000   \n",
       "7          lstm5                               (None, 48)           48   \n",
       "1          lstm1  [(None, 256), (None, 256), (None, 256)]          768   \n",
       "\n",
       "   stride_size strides  units  \n",
       "1          1.0    (1,)   -1.0  \n",
       "8         -1.0      -1    1.0  \n",
       "0         -1.0      -1   -1.0  \n",
       "2          2.0    (2,)   -1.0  \n",
       "4         -1.0      -1   32.0  \n",
       "6         -1.0      -1  128.0  \n",
       "3         -1.0      -1   10.0  \n",
       "5         -1.0      -1   64.0  \n",
       "7         -1.0      -1   48.0  \n",
       "1         -1.0      -1  256.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_rnn = pd.concat([cleaned_lstm, cleaned_seq2seq]).fillna(0)\n",
    "cleaned_rnn.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2942815167362537\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>filters</th>\n",
       "      <th>input_size</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>units</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.920884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.245781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>71</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>768</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.923542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>605</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>768</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.923542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activation_nan  activation_relu  activation_sigmoid  activation_tanh  \\\n",
       "5               0              0.0                 0.0                1   \n",
       "0               1              0.0                 0.0                0   \n",
       "1               0              0.0                 0.0                1   \n",
       "3               0              0.0                 0.0                1   \n",
       "\n",
       "   filters  input_size  kernel_size  output_size  stride_size  units  \\\n",
       "5     -1.0        8000         -1.0        16000         -1.0   64.0   \n",
       "0     -1.0         500         -1.0        16000         -1.0   -1.0   \n",
       "1     -1.0          71         -1.0          768         -1.0  256.0   \n",
       "3     -1.0         605         -1.0          768         -1.0  256.0   \n",
       "\n",
       "   avg_ms_actual  avg_ms_pred  \n",
       "5          0.940     0.920884  \n",
       "0          0.033     0.245781  \n",
       "1          0.382     0.923542  \n",
       "3          0.008     0.923542  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf, X_test, y_test = rf_regression_model(cleaned_rnn, '[avg ms]')\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "rnn_ms_rf_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 579.665771458365\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>filters</th>\n",
       "      <th>input_size</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>units</th>\n",
       "      <th>mem_kb_actual</th>\n",
       "      <th>mem_kb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32.000</td>\n",
       "      <td>32.800108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.000</td>\n",
       "      <td>28.480888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>71</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>768</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1.024</td>\n",
       "      <td>23.489068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>605</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>768</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>23.489068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activation_nan  activation_relu  activation_sigmoid  activation_tanh  \\\n",
       "5               0              0.0                 0.0                1   \n",
       "0               1              0.0                 0.0                0   \n",
       "1               0              0.0                 0.0                1   \n",
       "3               0              0.0                 0.0                1   \n",
       "\n",
       "   filters  input_size  kernel_size  output_size  stride_size  units  \\\n",
       "5     -1.0        8000         -1.0        16000         -1.0   64.0   \n",
       "0     -1.0         500         -1.0        16000         -1.0   -1.0   \n",
       "1     -1.0          71         -1.0          768         -1.0  256.0   \n",
       "3     -1.0         605         -1.0          768         -1.0  256.0   \n",
       "\n",
       "   mem_kb_actual  mem_kb_pred  \n",
       "5         32.000    32.800108  \n",
       "0         64.000    28.480888  \n",
       "1          1.024    23.489068  \n",
       "3          0.000    23.489068  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf, X_test, y_test = rf_regression_model(cleaned_rnn, '[mem KB]')\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "rnn_mem_rf_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_kb_actual': y_test, 'mem_kb_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2859937201506303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>filters</th>\n",
       "      <th>input_size</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>units</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.286428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.369030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.343472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>71</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>768</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.404815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activation_nan  activation_relu  activation_sigmoid  activation_tanh  \\\n",
       "6               0              0.0                 0.0                1   \n",
       "7               0              0.0                 0.0                1   \n",
       "5               0              0.0                 0.0                1   \n",
       "1               0              0.0                 0.0                1   \n",
       "\n",
       "   filters  input_size  kernel_size  output_size  stride_size  units  \\\n",
       "6     -1.0       16000         -1.0        32000         -1.0  128.0   \n",
       "7     -1.0       32000         -1.0           48         -1.0   48.0   \n",
       "5     -1.0        8000         -1.0        16000         -1.0   64.0   \n",
       "1     -1.0          71         -1.0          768         -1.0  256.0   \n",
       "\n",
       "   avg_ms_actual  avg_ms_pred  \n",
       "6          0.965     0.286428  \n",
       "7          0.941     0.369030  \n",
       "5          0.940     0.343472  \n",
       "1          0.382     0.404815  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr1, X_test, y_test = stacked_regression_model(cleaned_rnn, '[avg ms]')\n",
    "\n",
    "y_pred = sr1.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "rnn_ms_stacked_1_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 669.5076267904069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>filters</th>\n",
       "      <th>input_size</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>units</th>\n",
       "      <th>mem_kb_actual</th>\n",
       "      <th>mem_kb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.000</td>\n",
       "      <td>35.858307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>32.000</td>\n",
       "      <td>23.161030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>71</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>768</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1.024</td>\n",
       "      <td>4.029256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.000</td>\n",
       "      <td>21.586362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activation_nan  activation_relu  activation_sigmoid  activation_tanh  \\\n",
       "1               0              1.0                 0.0                0   \n",
       "7               0              0.0                 0.0                1   \n",
       "1               0              0.0                 0.0                1   \n",
       "0               1              0.0                 0.0                0   \n",
       "\n",
       "   filters  input_size  kernel_size  output_size  stride_size  units  \\\n",
       "1     32.0       16000          3.0        16000          1.0   -1.0   \n",
       "7     -1.0       32000         -1.0           48         -1.0   48.0   \n",
       "1     -1.0          71         -1.0          768         -1.0  256.0   \n",
       "0     -1.0         500         -1.0        16000         -1.0   -1.0   \n",
       "\n",
       "   mem_kb_actual  mem_kb_pred  \n",
       "1         64.000    35.858307  \n",
       "7         32.000    23.161030  \n",
       "1          1.024     4.029256  \n",
       "0         64.000    21.586362  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr1, X_test, y_test = stacked_regression_model(cleaned_rnn, '[mem KB]')\n",
    "\n",
    "y_pred = sr1.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "rnn_mem_stacked_1_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_kb_actual': y_test, 'mem_kb_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.3058684328711958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>filters</th>\n",
       "      <th>input_size</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>units</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.600031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>605</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>768</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.631573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.634437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.614179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activation_nan  activation_relu  activation_sigmoid  activation_tanh  \\\n",
       "4               0              0.0                 0.0                1   \n",
       "3               0              0.0                 0.0                1   \n",
       "2               1              0.0                 0.0                0   \n",
       "8               0              0.0                 1.0                0   \n",
       "\n",
       "   filters  input_size  kernel_size  output_size  stride_size  units  \\\n",
       "4     -1.0        2500         -1.0         8000         -1.0   32.0   \n",
       "3     -1.0         605         -1.0          768         -1.0  256.0   \n",
       "2     -1.0       16000         -1.0         8000          2.0   -1.0   \n",
       "8     -1.0          48         -1.0            1         -1.0    1.0   \n",
       "\n",
       "   avg_ms_actual  avg_ms_pred  \n",
       "4          0.941     0.600031  \n",
       "3          0.008     0.631573  \n",
       "2          0.039     0.634437  \n",
       "8          0.011     0.614179  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr2, X_test, y_test = stacked_regression_model_2(cleaned_rnn, '[avg ms]')\n",
    "\n",
    "y_pred = sr2.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "rnn_ms_stacked_2_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 570.5716243064076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>filters</th>\n",
       "      <th>input_size</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>units</th>\n",
       "      <th>mem_kb_actual</th>\n",
       "      <th>mem_kb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.000</td>\n",
       "      <td>37.493667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32.000</td>\n",
       "      <td>48.380956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>32.000</td>\n",
       "      <td>63.533541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004</td>\n",
       "      <td>17.808519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activation_nan  activation_relu  activation_sigmoid  activation_tanh  \\\n",
       "0               1              0.0                 0.0                0   \n",
       "5               0              0.0                 0.0                1   \n",
       "6               0              0.0                 0.0                1   \n",
       "8               0              0.0                 1.0                0   \n",
       "\n",
       "   filters  input_size  kernel_size  output_size  stride_size  units  \\\n",
       "0     -1.0         500         -1.0        16000         -1.0   -1.0   \n",
       "5     -1.0        8000         -1.0        16000         -1.0   64.0   \n",
       "6     -1.0       16000         -1.0        32000         -1.0  128.0   \n",
       "8     -1.0          48         -1.0            1         -1.0    1.0   \n",
       "\n",
       "   mem_kb_actual  mem_kb_pred  \n",
       "0         64.000    37.493667  \n",
       "5         32.000    48.380956  \n",
       "6         32.000    63.533541  \n",
       "8          0.004    17.808519  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr2, X_test, y_test = stacked_regression_model(cleaned_rnn, '[mem KB]')\n",
    "\n",
    "y_pred = sr2.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "rnn_mem_stacked_2_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_kb_actual': y_test, 'mem_kb_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgYAAAFlCAYAAACQtyDJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_ms = [cnn_ms_rf_mse, cnn_ms_stacked_1_mse,cnn_ms_stacked_2_mse]\n",
    "plt.bar([i*3 for i in range(len(cnn_ms))], cnn_ms, tick_label=[\n",
    "    'CNN Random Forest',\n",
    "    'CNN Stacked with RF',\n",
    "    'CNN Stacked with Polynomial',\n",
    "])\n",
    "plt.title('MSE of Regression of CNN Computation Time')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "plt.xlabel('Regressor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAFlCAYAAABlSat5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnn_ms = [rnn_ms_rf_mse, rnn_ms_stacked_1_mse, rnn_ms_stacked_2_mse]\n",
    "\n",
    "plt.bar([i*3 for i in range(len(rnn_ms))], rnn_ms, tick_label=[\n",
    "    'RNN Random Forest',\n",
    "    'RNN Stacked with RF',\n",
    "    'RNN Stacked with Polynomial',\n",
    "])\n",
    "plt.title('MSE of Regression of RNN Computation Time')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "plt.xlabel('Regressor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAggAAAFlCAYAAACOfhB6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLAQCAACwEAgAAMBCIAAAAMv/A84IZq+MK++ZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_mem = [cnn_mem_rf_mse, cnn_mem_stacked_1_mse]\n",
    "plt.bar(range(len(cnn_mem)), cnn_mem, tick_label=[\"Random Forest\", \"Stacked with RF\"])\n",
    "\n",
    "plt.title('MSE of Regression of CNN Memory Usage')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Regressor')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAFlCAYAAAAQ8morAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAxoLUw6Efh4oAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnn_mem = [rnn_mem_rf_mse, rnn_mem_stacked_1_mse, rnn_mem_stacked_2_mse]\n",
    "\n",
    "plt.bar(range(len(rnn_mem)), rnn_mem, tick_label=[\n",
    "    \"Random Forest\",\n",
    "    \"Stacked with RF\",\n",
    "    \"Stacked with Polynomial\",\n",
    "])\n",
    "\n",
    "plt.title('MSE of Regression of RNN Memory Usage')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Regressor')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
